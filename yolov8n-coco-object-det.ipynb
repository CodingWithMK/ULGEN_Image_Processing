{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1b723b",
   "metadata": {},
   "source": [
    "# **ULGEN - YOLO v8 Object Detection Model (COCO Subset)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab1081",
   "metadata": {},
   "source": [
    "## 1 - Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6c5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9d171",
   "metadata": {},
   "source": [
    "# 2 - Loading YAML and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bd1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "path: /content/datasets/coco\n",
    "train: images/train2017\n",
    "val: images/val2017\n",
    "names:\n",
    "  0: person\n",
    "  1: bicycle\n",
    "  2: car\n",
    "  3: motorcycle\n",
    "  4: airplane\n",
    "  5: bus\n",
    "  6: train\n",
    "  7: truck\n",
    "  8: boat\n",
    "  9: traffic light\n",
    "  10: fire hydrant\n",
    "  11: stop sign\n",
    "  12: parking meter\n",
    "  13: bench\n",
    "  14: bird\n",
    "  15: cat\n",
    "  16: dog\n",
    "  17: horse\n",
    "  18: sheep\n",
    "  19: cow\n",
    "  20: elephant\n",
    "  21: bear\n",
    "  22: zebra\n",
    "  23: giraffe\n",
    "  24: backpack\n",
    "  25: umbrella\n",
    "  26: handbag\n",
    "  27: tie\n",
    "  28: suitcase\n",
    "  29: frisbee\n",
    "  30: skis\n",
    "  31: snowboard\n",
    "  32: sports ball\n",
    "  33: kite\n",
    "  34: baseball bat\n",
    "  35: baseball glove\n",
    "  36: skateboard\n",
    "  37: surfboard\n",
    "  38: tennis racket\n",
    "  39: bottle\n",
    "  40: wine glass\n",
    "  41: cup\n",
    "  42: fork\n",
    "  43: knife\n",
    "  44: spoon\n",
    "  45: bowl\n",
    "  46: banana\n",
    "  47: apple\n",
    "  48: sandwich\n",
    "  49: orange\n",
    "  50: broccoli\n",
    "  51: carrot\n",
    "  52: hot dog\n",
    "  53: pizza\n",
    "  54: donut\n",
    "  55: cake\n",
    "  56: chair\n",
    "  57: couch\n",
    "  58: potted plant\n",
    "  59: bed\n",
    "  60: dining table\n",
    "  61: toilet\n",
    "  62: tv\n",
    "  63: laptop\n",
    "  64: mouse\n",
    "  65: remote\n",
    "  66: keyboard\n",
    "  67: cell phone\n",
    "  68: microwave\n",
    "  69: oven\n",
    "  70: toaster\n",
    "  71: sink\n",
    "  72: refrigerator\n",
    "  73: book\n",
    "  74: clock\n",
    "  75: vase\n",
    "  76: scissors\n",
    "  77: teddy bear\n",
    "  78: hair drier\n",
    "  79: toothbrush\n",
    "\"\"\"\n",
    "\n",
    "with open(\"./datasets/coco/coco.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5aa7c",
   "metadata": {},
   "source": [
    "# 3 - Converting COCO labels to YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f1a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def coco_to_yolo(coco_json, img_dir, out_label_dir):\n",
    "    os.makedirs(out_label_dir, exist_ok=True)\n",
    "    data = json.load(open(coco_json))\n",
    "    images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "    cats = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
    "    img_to_anns = {}\n",
    "\n",
    "    for ann in data[\"annotations\"]:\n",
    "        img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "    # Mapping COCO categories with ID's 0...79\n",
    "    cat_ids = sorted(cats.keys())\n",
    "    cat_to_idx = {cid: i for i, cid in enumerate(cat_ids)}\n",
    "\n",
    "    for img_id, meta in tqdm.tqdm(images.items()):\n",
    "        width, height = meta[\"width\"], meta[\"height\"]\n",
    "        anns = img_to_anns.get(img_id, [])\n",
    "        lines = []\n",
    "        for a in anns:\n",
    "            x, y, bw, bh = a[\"bbox\"]\n",
    "            cx, cy = x + bw / 2, y + bh / 2\n",
    "\n",
    "            # Normalize\n",
    "            nx, ny = cx / width, cy / height\n",
    "            nw, nh = bw / width, bh/ height\n",
    "            cls = cat_to_idx[a[\"category_id\"]]\n",
    "            lines.append(f\"{cls} {nx:.6f} {ny:.6f} {nw:.6f} {nh:.6f}\")\n",
    "        \n",
    "        # Label filename\n",
    "        stem = Path(meta[\"file_name\"]).stem\n",
    "        with open(os.path.join(out_label_dir, f\"{stem}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c31ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [01:39<00:00, 1185.75it/s]\n",
      "100%|██████████| 5000/5000 [00:03<00:00, 1316.14it/s]\n"
     ]
    }
   ],
   "source": [
    "coco_to_yolo(\"./datasets/coco/annotations/instances_train2017.json\", \"./datasets/coco/images/train2017\", \"./datasets/coco/labels/train2017\")\n",
    "coco_to_yolo(\"./datasets/coco/annotations/instances_val2017.json\", \"./datasets/coco/images/val2017\", \"./datasets/coco/labels/val2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad79ec",
   "metadata": {},
   "source": [
    "# 4 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2473f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO(\n",
      "  (model): DetectionModel(\n",
      "    (model): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (4): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0-1): 2 x Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (6): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0-1): 2 x Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Conv(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (8): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): SPPF(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (11): Concat()\n",
      "      (12): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (14): Concat()\n",
      "      (15): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (17): Concat()\n",
      "      (18): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (20): Concat()\n",
      "      (21): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): Detect(\n",
      "        (cv2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (cv3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (dfl): DFL(\n",
      "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0e9e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b747fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.10.18 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./datasets/coco/coco.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 186.7128.4 MB/s, size: 146.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\datasets\\coco\\labels\\train2017.cache... 11829 images, 109 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 11829/11829 11.6Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.2 ms, read: 132.648.6 MB/s, size: 180.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\datasets\\coco\\labels\\val2017.cache... 5000 images, 48 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5000/5000 5.0Mit/s 0.0s\n",
      "Plotting labels to C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100     0.932G      1.258      1.573      1.248         35        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:47<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.3it/s 33.6s<0.1ss\n",
      "                   all       5000      36781       0.53       0.38      0.393      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100       1.1G       1.34      1.787      1.296         90        512: 100% ━━━━━━━━━━━━ 1479/1479 9.8it/s 2:30<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 10.0it/s 31.2s0.2ss\n",
      "                   all       5000      36781      0.451      0.298      0.286      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100       1.1G       1.48      2.141      1.393         98        512: 100% ━━━━━━━━━━━━ 1479/1479 9.0it/s 2:45<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.0s<0.1s\n",
      "                   all       5000      36781      0.361      0.211      0.183      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      1.11G      1.596      2.438      1.479         47        512: 100% ━━━━━━━━━━━━ 1479/1479 9.0it/s 2:44<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.7s<0.1s\n",
      "                   all       5000      36781      0.312      0.205      0.167     0.0994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      1.11G      1.559      2.381      1.461        108        512: 100% ━━━━━━━━━━━━ 1479/1479 9.1it/s 2:43<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.6s<0.1s\n",
      "                   all       5000      36781      0.329      0.225      0.187      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      1.11G      1.537      2.306      1.447         81        512: 100% ━━━━━━━━━━━━ 1479/1479 9.1it/s 2:43<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.9s<0.1s\n",
      "                   all       5000      36781      0.381      0.228      0.198      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      1.11G      1.516      2.247      1.431         48        512: 100% ━━━━━━━━━━━━ 1479/1479 9.3it/s 2:399<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.9it/s 31.6s<0.1ss\n",
      "                   all       5000      36781      0.371      0.245      0.215      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      1.11G      1.503        2.2      1.422         87        512: 100% ━━━━━━━━━━━━ 1479/1479 10.1it/s 2:270.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.4it/s 33.3s<0.1ss\n",
      "                   all       5000      36781      0.378      0.257      0.226      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      1.11G      1.476      2.145      1.408         75        512: 100% ━━━━━━━━━━━━ 1479/1479 9.2it/s 2:40<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.3it/s 33.7s<0.1s\n",
      "                   all       5000      36781      0.389      0.264      0.244      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      1.11G      1.469      2.125      1.401         59        512: 100% ━━━━━━━━━━━━ 1479/1479 9.4it/s 2:37<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.2s<0.1s\n",
      "                   all       5000      36781      0.402      0.267      0.246      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      1.11G      1.453      2.077      1.394         98        512: 100% ━━━━━━━━━━━━ 1479/1479 8.7it/s 2:50<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.0s<0.1s\n",
      "                   all       5000      36781      0.401      0.274      0.254       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      1.11G      1.442      2.057      1.385         38        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:51<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.6it/s 36.3s<0.1s\n",
      "                   all       5000      36781      0.425      0.271      0.261      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      1.11G       1.43      2.024      1.379         92        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:34<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.3it/s 33.8s<0.1s\n",
      "                   all       5000      36781      0.424       0.28      0.265      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      1.11G      1.427      2.006      1.377        112        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:34<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.2it/s 34.0s<0.1s\n",
      "                   all       5000      36781      0.448      0.285      0.276      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      1.11G      1.416      1.987      1.368         69        512: 100% ━━━━━━━━━━━━ 1479/1479 9.0it/s 2:45<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.424      0.292      0.281      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      1.11G      1.412      1.956      1.363        100        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.451      0.291      0.282      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      1.11G      1.409      1.941      1.357         54        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 37.0s<0.1s\n",
      "                   all       5000      36781      0.454      0.295      0.289      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      1.11G      1.395      1.922      1.353         36        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:46<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.1s<0.1s\n",
      "                   all       5000      36781      0.442      0.301      0.297      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      1.11G        1.4      1.907      1.353         92        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:46<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.445      0.301      0.297      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      1.11G      1.387      1.879      1.347         40        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:344<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.9it/s 31.8s<0.2ss\n",
      "                   all       5000      36781      0.478      0.309      0.307      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      1.11G      1.384      1.886      1.348         73        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:34<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.6s<0.1s\n",
      "                   all       5000      36781      0.455      0.313      0.306      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      1.11G      1.377      1.858      1.336        102        512: 100% ━━━━━━━━━━━━ 1479/1479 9.2it/s 2:41<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.6it/s 36.2s<0.1s\n",
      "                   all       5000      36781      0.446      0.317      0.311      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      1.11G      1.372       1.84      1.334         79        512: 100% ━━━━━━━━━━━━ 1479/1479 9.2it/s 2:40<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.6it/s 36.2s<0.1s\n",
      "                   all       5000      36781      0.466      0.314      0.319      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      1.11G      1.369      1.832      1.329         65        512: 100% ━━━━━━━━━━━━ 1479/1479 9.3it/s 2:39<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.7it/s 35.8s<0.1s\n",
      "                   all       5000      36781       0.46      0.324       0.32      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      1.11G      1.362      1.813      1.327         62        512: 100% ━━━━━━━━━━━━ 1479/1479 9.3it/s 2:40<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.7it/s 36.0s<0.1s\n",
      "                   all       5000      36781       0.48       0.32      0.325      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      1.11G      1.362      1.809      1.328        102        512: 100% ━━━━━━━━━━━━ 1479/1479 9.3it/s 2:40<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.1it/s 34.2s<0.1s\n",
      "                   all       5000      36781      0.476      0.327      0.326      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      1.11G      1.352      1.794      1.323         43        512: 100% ━━━━━━━━━━━━ 1479/1479 9.4it/s 2:37<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.2it/s 34.1ss<0.1s\n",
      "                   all       5000      36781       0.49      0.327      0.331      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      1.11G       1.35      1.798      1.323         61        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 37.0s<0.1s\n",
      "                   all       5000      36781       0.51      0.325      0.336      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      1.11G      1.339      1.766      1.315         89        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:46<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.496      0.332      0.339      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      1.11G      1.343      1.763      1.313         88        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.481       0.33      0.339      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      1.11G      1.339      1.751      1.314         69        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.507      0.336      0.346      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      1.11G      1.337      1.752      1.313        110        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:46<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 37.0s<0.1s\n",
      "                   all       5000      36781      0.506      0.341       0.35       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      1.11G      1.333      1.731      1.308         27        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.0s<0.1s\n",
      "                   all       5000      36781      0.491      0.344      0.352      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      1.11G      1.332      1.719      1.305         63        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.7s<0.1s\n",
      "                   all       5000      36781        0.5      0.343      0.354      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      1.11G      1.324      1.705      1.302         39        512: 100% ━━━━━━━━━━━━ 1479/1479 8.7it/s 2:49<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.2s<0.1s\n",
      "                   all       5000      36781      0.502      0.346      0.355      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      1.11G      1.327      1.704      1.301         42        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.0s<0.1s\n",
      "                   all       5000      36781      0.509      0.343      0.356      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      1.11G      1.317      1.695      1.297         75        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.8s<0.1s\n",
      "                   all       5000      36781      0.501      0.349      0.358      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      1.11G      1.317      1.698      1.298         44        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.509      0.351      0.357      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      1.11G      1.313       1.68      1.293         70        512: 100% ━━━━━━━━━━━━ 1479/1479 8.7it/s 2:49<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.2s<0.1s\n",
      "                   all       5000      36781      0.511      0.346      0.359      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      1.11G      1.304      1.662      1.291         71        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.533      0.346      0.363      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      1.11G      1.306      1.659       1.29         61        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.513      0.354      0.366      0.244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      1.11G      1.302       1.66       1.29         84        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:47<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.509      0.357      0.368      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      1.11G      1.306      1.648      1.286         69        512: 100% ━━━━━━━━━━━━ 1479/1479 9.1it/s 2:42<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.6it/s 32.5s<0.2s\n",
      "                   all       5000      36781      0.519      0.355       0.37      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      1.11G      1.296      1.631      1.285         53        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:34<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s0.2ss\n",
      "                   all       5000      36781      0.516      0.357      0.372      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      1.11G      1.292      1.639      1.282        131        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.515       0.36      0.372      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      1.11G      1.294      1.629      1.279         78        512: 100% ━━━━━━━━━━━━ 1479/1479 8.4it/s 2:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.508      0.362      0.373      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      1.11G       1.29      1.598      1.276         49        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.512      0.362      0.375      0.251\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      1.11G      1.289      1.611      1.276         34        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.523      0.363      0.377      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      1.11G      1.283        1.6      1.273         57        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.512      0.367      0.377      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      1.11G      1.281      1.594      1.274         73        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.514      0.368       0.38      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      1.11G      1.277      1.584      1.269         60        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.517      0.375      0.382      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      1.11G      1.279      1.585      1.269         93        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.519      0.372      0.382      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      1.11G      1.275      1.573      1.268         62        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.513      0.377      0.382      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      1.11G      1.269      1.564      1.265         56        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781       0.53      0.369      0.382      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      1.11G      1.269      1.557      1.263         54        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.526      0.368      0.384      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      1.11G      1.261      1.546      1.259         60        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.3s<0.1s\n",
      "                   all       5000      36781      0.524       0.37      0.384      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      1.11G      1.266      1.552      1.261         87        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.532      0.368      0.385      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      1.11G      1.257      1.535      1.259         71        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.532       0.37      0.385       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      1.11G      1.256       1.53      1.256         81        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.2s<0.1s\n",
      "                   all       5000      36781      0.539      0.366      0.386       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      1.11G      1.252      1.526      1.251         85        512: 100% ━━━━━━━━━━━━ 1479/1479 8.4it/s 2:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.0s<0.1s\n",
      "                   all       5000      36781      0.538      0.368      0.389      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      1.11G      1.254      1.518      1.252         50        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.9s<0.1s\n",
      "                   all       5000      36781      0.543      0.369       0.39      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      1.11G      1.251      1.514      1.252         82        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.544      0.369      0.391      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      1.11G       1.25      1.506      1.247         49        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.2s<0.1s\n",
      "                   all       5000      36781      0.539      0.372      0.392      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      1.11G      1.245      1.493      1.249         39        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.535      0.373      0.393      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      1.11G      1.245      1.495      1.246         71        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.541      0.372      0.392      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      1.11G      1.241      1.491      1.246         53        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781       0.54      0.372      0.392      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      1.11G      1.233      1.477      1.241        115        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:53<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.9s<0.1s\n",
      "                   all       5000      36781      0.527       0.38      0.393      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      1.11G       1.23      1.471      1.237         66        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.529      0.379      0.393      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      1.11G      1.235       1.47      1.238         90        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.4s<0.1s\n",
      "                   all       5000      36781      0.529      0.382      0.394      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      1.11G      1.227      1.457      1.236         79        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781      0.529      0.381      0.395      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      1.11G      1.225      1.454      1.235         76        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.9s<0.1s\n",
      "                   all       5000      36781      0.523      0.383      0.395      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      1.11G      1.226      1.448      1.232         71        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.526      0.383      0.395      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      1.11G      1.222      1.433       1.23         50        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.6s<0.1s\n",
      "                   all       5000      36781      0.525      0.382      0.395      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      1.11G      1.215      1.433       1.23         99        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.3it/s 37.5s<0.1s\n",
      "                   all       5000      36781       0.53       0.38      0.395      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      1.11G      1.219      1.427      1.229         31        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.528      0.381      0.395      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      1.11G      1.221      1.429       1.23         59        512: 100% ━━━━━━━━━━━━ 1479/1479 8.7it/s 2:51<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.2it/s 38.4s<0.2s\n",
      "                   all       5000      36781      0.533      0.379      0.395      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      1.11G      1.207      1.408      1.222         95        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:53<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.2s<0.1s\n",
      "                   all       5000      36781       0.52      0.382      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      1.11G      1.206       1.41      1.222         69        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.3s<0.1s\n",
      "                   all       5000      36781      0.518      0.383      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      1.11G      1.205        1.4      1.221         24        512: 100% ━━━━━━━━━━━━ 1479/1479 8.6it/s 2:52<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.4it/s 37.2s<0.1s\n",
      "                   all       5000      36781      0.516      0.384      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      1.11G      1.204        1.4       1.22         34        512: 100% ━━━━━━━━━━━━ 1479/1479 8.5it/s 2:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.8it/s 35.6s0.2ss\n",
      "                   all       5000      36781      0.524      0.382      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      1.11G      1.202       1.39       1.22         54        512: 100% ━━━━━━━━━━━━ 1479/1479 9.9it/s 2:300<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.6it/s 32.7s<0.1ss\n",
      "                   all       5000      36781      0.525      0.381      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      1.11G      1.198      1.383      1.216         51        512: 100% ━━━━━━━━━━━━ 1479/1479 9.1it/s 2:42<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.6it/s 36.5s<0.1s\n",
      "                   all       5000      36781      0.526      0.383      0.396      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      1.11G      1.202      1.385      1.217         65        512: 100% ━━━━━━━━━━━━ 1479/1479 9.0it/s 2:44<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.6s<0.1s\n",
      "                   all       5000      36781      0.528      0.381      0.397      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      1.11G      1.192      1.375      1.215         60        512: 100% ━━━━━━━━━━━━ 1479/1479 9.0it/s 2:44<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.5it/s 36.6s<0.1s\n",
      "                   all       5000      36781      0.534       0.38      0.397      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      1.11G      1.188      1.366      1.213         49        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:488<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.9it/s 39.6s<0.1s\n",
      "                   all       5000      36781      0.536       0.38      0.397      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      1.11G      1.185      1.357       1.21         61        512: 100% ━━━━━━━━━━━━ 1479/1479 8.3it/s 2:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.9it/s 39.8s<0.1s\n",
      "                   all       5000      36781      0.537       0.38      0.397      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      1.11G      1.189      1.354       1.21         93        512: 100% ━━━━━━━━━━━━ 1479/1479 8.4it/s 2:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all       5000      36781      0.536       0.38      0.397      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      1.11G       1.18      1.346      1.207         77        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.7it/s 36.1s0.2ss\n",
      "                   all       5000      36781      0.536       0.38      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      1.11G      1.189      1.344      1.208         32        512: 100% ━━━━━━━━━━━━ 1479/1479 8.9it/s 2:46<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.9it/s 39.6s<0.1s\n",
      "                   all       5000      36781      0.537       0.38      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      1.11G      1.179      1.335      1.203         48        512: 100% ━━━━━━━━━━━━ 1479/1479 8.3it/s 2:58<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.9it/s 39.4s<0.1s\n",
      "                   all       5000      36781      0.534      0.383      0.398      0.269\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      1.11G       1.16      1.224      1.185         44        512: 100% ━━━━━━━━━━━━ 1479/1479 8.4it/s 2:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.9it/s 39.7s<0.1s\n",
      "                   all       5000      36781      0.538      0.381      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      1.11G      1.142      1.194      1.174         26        512: 100% ━━━━━━━━━━━━ 1479/1479 9.2it/s 2:41<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.3it/s 43.0s<0.1s\n",
      "                   all       5000      36781      0.536      0.383      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      1.11G      1.133      1.175      1.171         28        512: 100% ━━━━━━━━━━━━ 1479/1479 7.9it/s 3:07<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.6it/s 41.4s<0.1s\n",
      "                   all       5000      36781      0.534      0.384      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      1.11G      1.137      1.174       1.17         39        512: 100% ━━━━━━━━━━━━ 1479/1479 7.8it/s 3:09<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 7.7it/s 40.7s<0.1s\n",
      "                   all       5000      36781      0.533      0.383      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      1.11G      1.132      1.164      1.169         37        512: 100% ━━━━━━━━━━━━ 1479/1479 8.8it/s 2:48<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.6it/s 36.6s0.2ss\n",
      "                   all       5000      36781      0.533      0.384      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      1.11G      1.126      1.151      1.167         44        512: 100% ━━━━━━━━━━━━ 1479/1479 10.4it/s 2:22<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 10.2it/s 30.7s<0.1s\n",
      "                   all       5000      36781      0.534      0.384      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      1.11G      1.125      1.146      1.163         23        512: 100% ━━━━━━━━━━━━ 1479/1479 9.9it/s 2:29<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 10.0it/s 31.2s<0.1s\n",
      "                   all       5000      36781      0.534      0.383      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      1.11G      1.123      1.137      1.162         10        512: 100% ━━━━━━━━━━━━ 1479/1479 10.4it/s 2:22<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 10.3it/s 30.5s0.2ss\n",
      "                   all       5000      36781      0.535      0.382      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      1.11G      1.118       1.13      1.159         36        512: 100% ━━━━━━━━━━━━ 1479/1479 9.5it/s 2:36<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 8.7it/s 36.1s<0.1s\n",
      "                   all       5000      36781      0.534      0.383      0.398      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      1.11G      1.116      1.122      1.157         23        512: 100% ━━━━━━━━━━━━ 1479/1479 9.6it/s 2:344<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 9.2it/s 33.9ss<0.1s\n",
      "                   all       5000      36781      0.535      0.382      0.398      0.269\n",
      "\n",
      "100 epochs completed in 5.713 hours.\n",
      "Optimizer stripped from C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating C:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.10.18 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 313/313 10.6it/s 29.5s0.2ss\n",
      "                   all       5000      36781      0.532      0.384      0.398       0.27\n",
      "                person       2693      11004      0.726        0.6      0.671      0.437\n",
      "               bicycle        149        316      0.571       0.32      0.329      0.174\n",
      "                   car        535       1932      0.593      0.411      0.444      0.271\n",
      "            motorcycle        159        371       0.64      0.474      0.543      0.318\n",
      "              airplane         97        143      0.725      0.657       0.71      0.515\n",
      "                   bus        189        285      0.734      0.565      0.623      0.508\n",
      "                 train        157        190      0.669        0.7      0.763      0.575\n",
      "                 truck        250        415       0.51       0.32      0.362      0.222\n",
      "                  boat        121        430      0.475      0.258       0.27      0.123\n",
      "         traffic light        191        637      0.527      0.234       0.27      0.133\n",
      "          fire hydrant         86        101      0.795      0.652      0.724      0.563\n",
      "             stop sign         69         75      0.623        0.6      0.625      0.556\n",
      "         parking meter         37         60       0.63      0.312      0.387      0.292\n",
      "                 bench        235        413      0.476      0.207      0.222      0.138\n",
      "                  bird        125        440      0.474      0.245      0.275      0.168\n",
      "                   cat        184        202      0.661      0.724      0.756      0.543\n",
      "                   dog        177        218      0.566      0.573      0.583      0.473\n",
      "                 horse        128        273      0.656       0.59      0.637      0.438\n",
      "                 sheep         65        361      0.527      0.543      0.542      0.341\n",
      "                   cow         87        380      0.645      0.479      0.547      0.361\n",
      "              elephant         89        255      0.646      0.737      0.737      0.514\n",
      "                  bear         49         71      0.711      0.634      0.653      0.527\n",
      "                 zebra         85        268       0.76      0.731      0.807      0.569\n",
      "               giraffe        101        232      0.772      0.772      0.803      0.611\n",
      "              backpack        228        371      0.334     0.0836      0.108      0.057\n",
      "              umbrella        174        413      0.603       0.39      0.412      0.251\n",
      "               handbag        292        540      0.373     0.0795     0.0885     0.0435\n",
      "                   tie        145        254      0.522      0.287       0.31      0.185\n",
      "              suitcase        105        303      0.461       0.29      0.296      0.186\n",
      "               frisbee         84        115      0.654      0.591      0.604      0.447\n",
      "                  skis        120        241      0.458      0.245      0.239      0.113\n",
      "             snowboard         49         69      0.384      0.203      0.217       0.14\n",
      "           sports ball        169        263      0.632      0.319      0.362      0.244\n",
      "                  kite         91        336      0.514      0.452      0.449      0.277\n",
      "          baseball bat         97        146      0.459       0.26      0.227        0.1\n",
      "        baseball glove        100        148      0.573      0.372      0.374      0.203\n",
      "            skateboard        127        179      0.572      0.514       0.51      0.321\n",
      "             surfboard        149        269      0.579      0.368      0.365      0.197\n",
      "         tennis racket        167        225      0.612      0.484      0.531      0.294\n",
      "                bottle        379       1025      0.506      0.307      0.322       0.19\n",
      "            wine glass        110        343      0.538      0.227      0.258      0.163\n",
      "                   cup        390        899      0.506       0.34      0.348       0.23\n",
      "                  fork        155        215      0.424      0.233      0.237      0.146\n",
      "                 knife        181        326      0.285     0.0613     0.0789       0.04\n",
      "                 spoon        153        253      0.196     0.0356     0.0399     0.0211\n",
      "                  bowl        314        626      0.515      0.422       0.41      0.298\n",
      "                banana        103        379      0.368      0.179      0.207      0.115\n",
      "                 apple         76        239      0.262      0.159      0.116     0.0727\n",
      "              sandwich         98        177      0.494      0.359      0.337      0.224\n",
      "                orange         85        287      0.344      0.341      0.259      0.194\n",
      "              broccoli         71        316      0.401      0.332      0.296      0.157\n",
      "                carrot         81        371      0.395      0.199      0.199       0.11\n",
      "               hot dog         51        127      0.414      0.189      0.216      0.149\n",
      "                 pizza        153        285      0.593      0.589      0.595      0.431\n",
      "                 donut         62        338      0.419      0.299      0.285      0.218\n",
      "                  cake        124        316       0.41      0.247      0.261      0.163\n",
      "                 chair        580       1791      0.476      0.239      0.266      0.157\n",
      "                 couch        195        261      0.464      0.517      0.475      0.324\n",
      "          potted plant        172        343      0.454      0.297      0.261      0.133\n",
      "                   bed        149        163      0.517      0.509      0.503      0.349\n",
      "          dining table        501        697      0.494       0.42      0.378      0.254\n",
      "                toilet        149        179      0.641      0.659      0.669      0.527\n",
      "                    tv        207        288      0.683      0.576       0.63      0.469\n",
      "                laptop        183        231      0.584      0.541      0.567      0.443\n",
      "                 mouse         88        106      0.522      0.577      0.588      0.448\n",
      "                remote        145        283      0.436      0.138      0.156     0.0825\n",
      "              keyboard        106        153      0.532      0.503      0.527      0.363\n",
      "            cell phone        214        262      0.582      0.286       0.31      0.216\n",
      "             microwave         54         55      0.513      0.418      0.455      0.368\n",
      "                  oven        115        143      0.482      0.399      0.391      0.238\n",
      "               toaster          8          9      0.463      0.111      0.114     0.0859\n",
      "                  sink        187        225      0.506        0.4      0.386      0.238\n",
      "          refrigerator        101        126      0.604      0.548      0.505      0.361\n",
      "                  book        230       1161       0.32      0.106      0.115     0.0494\n",
      "                 clock        204        267      0.594      0.591       0.57       0.37\n",
      "                  vase        137        277       0.45      0.321      0.329      0.215\n",
      "              scissors         28         36      0.401      0.194      0.195      0.141\n",
      "            teddy bear         94        191      0.585      0.487      0.488      0.323\n",
      "            hair drier          9         11          1          0     0.0161    0.00586\n",
      "            toothbrush         34         57      0.327      0.103     0.0877      0.051\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\musab\\Documents\\ULGEN_Image_Processing\\runs\\detect\\train7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"./datasets/coco/coco.yaml\", epochs=100, imgsz=512, batch=8, fraction=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f09a3",
   "metadata": {},
   "source": [
    "# 4 - Model Evaluation / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41943bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x512 13 persons, 1 car, 1 traffic light, 23.1ms\n",
      "Speed: 12.4ms preprocess, 23.1ms inference, 16.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 1 traffic light, 22.5ms\n",
      "Speed: 2.5ms preprocess, 22.5ms inference, 14.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 1 traffic light, 19.6ms\n",
      "Speed: 2.5ms preprocess, 19.6ms inference, 18.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 20.3ms\n",
      "Speed: 2.6ms preprocess, 20.3ms inference, 15.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 1 traffic light, 19.3ms\n",
      "Speed: 2.3ms preprocess, 19.3ms inference, 19.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 20.2ms\n",
      "Speed: 5.8ms preprocess, 20.2ms inference, 24.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 26.2ms\n",
      "Speed: 3.4ms preprocess, 26.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 22.7ms\n",
      "Speed: 2.4ms preprocess, 22.7ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 bus, 1 traffic light, 16.8ms\n",
      "Speed: 2.9ms preprocess, 16.8ms inference, 22.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 2 traffic lights, 16.7ms\n",
      "Speed: 2.3ms preprocess, 16.7ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 16.9ms\n",
      "Speed: 3.4ms preprocess, 16.9ms inference, 12.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 bus, 1 traffic light, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 16.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bus, 1 traffic light, 24.2ms\n",
      "Speed: 2.8ms preprocess, 24.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 16.5ms\n",
      "Speed: 2.4ms preprocess, 16.5ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 bus, 1 traffic light, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 17.0ms\n",
      "Speed: 2.6ms preprocess, 17.0ms inference, 20.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 4 persons, 1 car, 1 bus, 1 traffic light, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 4 persons, 2 cars, 1 bus, 1 traffic light, 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 bus, 1 traffic light, 20.8ms\n",
      "Speed: 2.8ms preprocess, 20.8ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 1 bus, 1 traffic light, 20.9ms\n",
      "Speed: 2.9ms preprocess, 20.9ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 bus, 2 traffic lights, 20.5ms\n",
      "Speed: 2.5ms preprocess, 20.5ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 20.7ms\n",
      "Speed: 2.6ms preprocess, 20.7ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 20.9ms\n",
      "Speed: 2.3ms preprocess, 20.9ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 18.8ms\n",
      "Speed: 2.4ms preprocess, 18.8ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 18.6ms\n",
      "Speed: 2.4ms preprocess, 18.6ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 bus, 1 traffic light, 18.7ms\n",
      "Speed: 2.4ms preprocess, 18.7ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 bus, 1 traffic light, 19.2ms\n",
      "Speed: 2.7ms preprocess, 19.2ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 17.8ms\n",
      "Speed: 2.4ms preprocess, 17.8ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 18.8ms\n",
      "Speed: 2.3ms preprocess, 18.8ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 bus, 1 traffic light, 17.9ms\n",
      "Speed: 2.4ms preprocess, 17.9ms inference, 17.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 3 suitcases, 18.0ms\n",
      "Speed: 3.7ms preprocess, 18.0ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 18.1ms\n",
      "Speed: 2.4ms preprocess, 18.1ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 18.2ms\n",
      "Speed: 3.0ms preprocess, 18.2ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 18.1ms\n",
      "Speed: 2.2ms preprocess, 18.1ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 18.1ms\n",
      "Speed: 3.1ms preprocess, 18.1ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 17.9ms\n",
      "Speed: 2.3ms preprocess, 17.9ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 bus, 1 traffic light, 23.4ms\n",
      "Speed: 2.5ms preprocess, 23.4ms inference, 18.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 19.7ms\n",
      "Speed: 3.9ms preprocess, 19.7ms inference, 22.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 17.2ms\n",
      "Speed: 2.4ms preprocess, 17.2ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 3.3ms preprocess, 17.3ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 1 bus, 1 traffic light, 2 suitcases, 17.3ms\n",
      "Speed: 2.1ms preprocess, 17.3ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 2 cars, 1 bus, 1 traffic light, 1 suitcase, 17.5ms\n",
      "Speed: 2.3ms preprocess, 17.5ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 bus, 1 traffic light, 1 suitcase, 17.2ms\n",
      "Speed: 2.6ms preprocess, 17.2ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 bus, 1 traffic light, 1 suitcase, 18.7ms\n",
      "Speed: 3.3ms preprocess, 18.7ms inference, 15.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 bus, 1 traffic light, 1 suitcase, 17.4ms\n",
      "Speed: 2.8ms preprocess, 17.4ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 16.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 1 suitcase, 17.5ms\n",
      "Speed: 3.1ms preprocess, 17.5ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bus, 1 traffic light, 1 suitcase, 17.0ms\n",
      "Speed: 2.4ms preprocess, 17.0ms inference, 14.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bus, 1 traffic light, 1 suitcase, 17.2ms\n",
      "Speed: 2.3ms preprocess, 17.2ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 bus, 1 traffic light, 17.4ms\n",
      "Speed: 2.3ms preprocess, 17.4ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 bus, 1 traffic light, 17.5ms\n",
      "Speed: 2.4ms preprocess, 17.5ms inference, 12.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 bus, 1 traffic light, 17.3ms\n",
      "Speed: 2.7ms preprocess, 17.3ms inference, 21.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bus, 1 traffic light, 1 suitcase, 17.7ms\n",
      "Speed: 2.4ms preprocess, 17.7ms inference, 18.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 bus, 1 traffic light, 2 suitcases, 17.2ms\n",
      "Speed: 3.9ms preprocess, 17.2ms inference, 14.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bus, 1 traffic light, 2 suitcases, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 2 suitcases, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 2 suitcases, 17.7ms\n",
      "Speed: 2.4ms preprocess, 17.7ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 17.2ms\n",
      "Speed: 2.6ms preprocess, 17.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bus, 1 traffic light, 1 suitcase, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 3.1ms preprocess, 17.3ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bus, 1 traffic light, 1 suitcase, 17.3ms\n",
      "Speed: 2.9ms preprocess, 17.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 17.4ms\n",
      "Speed: 3.4ms preprocess, 17.4ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 2 traffic lights, 1 suitcase, 18.2ms\n",
      "Speed: 2.1ms preprocess, 18.2ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 17.9ms\n",
      "Speed: 2.4ms preprocess, 17.9ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 1 suitcase, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 1 suitcase, 17.9ms\n",
      "Speed: 2.4ms preprocess, 17.9ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.8ms\n",
      "Speed: 2.9ms preprocess, 16.8ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 17.0ms\n",
      "Speed: 3.7ms preprocess, 17.0ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.9ms\n",
      "Speed: 2.4ms preprocess, 16.9ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.5ms\n",
      "Speed: 3.4ms preprocess, 16.5ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 16.7ms\n",
      "Speed: 2.4ms preprocess, 16.7ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 traffic light, 16.6ms\n",
      "Speed: 3.7ms preprocess, 16.6ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 traffic light, 1 suitcase, 16.7ms\n",
      "Speed: 2.4ms preprocess, 16.7ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bus, 1 traffic light, 16.6ms\n",
      "Speed: 3.6ms preprocess, 16.6ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 17.2ms\n",
      "Speed: 2.4ms preprocess, 17.2ms inference, 16.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 16.5ms\n",
      "Speed: 2.7ms preprocess, 16.5ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bus, 1 traffic light, 1 suitcase, 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 16.6ms\n",
      "Speed: 2.5ms preprocess, 16.6ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bus, 1 traffic light, 1 suitcase, 16.5ms\n",
      "Speed: 2.7ms preprocess, 16.5ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 handbag, 1 suitcase, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 handbag, 1 suitcase, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 1 suitcase, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 suitcase, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 15.5ms\n",
      "Speed: 3.3ms preprocess, 15.5ms inference, 13.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 suitcase, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 suitcase, 16.1ms\n",
      "Speed: 2.6ms preprocess, 16.1ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.7ms preprocess, 15.8ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 1 suitcase, 15.0ms\n",
      "Speed: 2.9ms preprocess, 15.0ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 15.9ms\n",
      "Speed: 3.1ms preprocess, 15.9ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 2 suitcases, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 12.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 suitcase, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 1 suitcase, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 1 suitcase, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 17.9ms\n",
      "Speed: 3.0ms preprocess, 17.9ms inference, 12.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 traffic lights, 1 suitcase, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 13.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 backpack, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.4ms\n",
      "Speed: 3.3ms preprocess, 16.4ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 19.5ms\n",
      "Speed: 2.5ms preprocess, 19.5ms inference, 21.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.4ms\n",
      "Speed: 2.6ms preprocess, 16.4ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 17.1ms\n",
      "Speed: 2.6ms preprocess, 17.1ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 15.3ms\n",
      "Speed: 2.4ms preprocess, 15.3ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 17.1ms\n",
      "Speed: 3.5ms preprocess, 17.1ms inference, 14.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 traffic lights, 15.8ms\n",
      "Speed: 3.1ms preprocess, 15.8ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 1 suitcase, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 suitcase, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 1 suitcase, 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 persons, 1 traffic light, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 3 traffic lights, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 14.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 13.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 3 traffic lights, 3 suitcases, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 3 suitcases, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 1 suitcase, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 1 suitcase, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 2 suitcases, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 1 stop sign, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 1 suitcase, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 1 suitcase, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 2 traffic lights, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 11.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 suitcase, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 12.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 1 suitcase, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 13.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 backpack, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 backpack, 1 suitcase, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 11.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 19.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 1 suitcase, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 15.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 2 traffic lights, 1 suitcase, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 13.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 1 suitcase, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 13.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 2 traffic lights, 1 suitcase, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 1 suitcase, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 2 traffic lights, 1 suitcase, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 13.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 1 suitcase, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 11.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 1 suitcase, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 11.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 1 suitcase, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 12.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 16.5ms\n",
      "Speed: 2.3ms preprocess, 16.5ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 16.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 1 suitcase, 16.5ms\n",
      "Speed: 2.6ms preprocess, 16.5ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.1ms\n",
      "Speed: 5.2ms preprocess, 16.1ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 13.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 traffic light, 16.0ms\n",
      "Speed: 3.7ms preprocess, 16.0ms inference, 19.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 2 traffic lights, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 14.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 2 traffic lights, 15.1ms\n",
      "Speed: 2.3ms preprocess, 15.1ms inference, 13.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 2 traffic lights, 1 suitcase, 15.9ms\n",
      "Speed: 1.9ms preprocess, 15.9ms inference, 12.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 car, 1 traffic light, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 2 traffic lights, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 2 traffic lights, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 12.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 15.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 2 traffic lights, 15.0ms\n",
      "Speed: 2.3ms preprocess, 15.0ms inference, 21.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 14.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 traffic light, 1 suitcase, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 suitcase, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 traffic light, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 persons, 1 car, 1 traffic light, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 car, 2 traffic lights, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 car, 2 traffic lights, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 12.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 car, 3 traffic lights, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 1 car, 2 traffic lights, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 16.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 persons, 2 traffic lights, 22.6ms\n",
      "Speed: 2.2ms preprocess, 22.6ms inference, 24.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 11.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 13.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 2 traffic lights, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 2 traffic lights, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 17.1ms\n",
      "Speed: 2.2ms preprocess, 17.1ms inference, 14.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 2 traffic lights, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 traffic lights, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 traffic lights, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 19.1ms\n",
      "Speed: 2.3ms preprocess, 19.1ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.4ms\n",
      "Speed: 2.6ms preprocess, 16.4ms inference, 23.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.2ms\n",
      "Speed: 2.8ms preprocess, 16.2ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 13.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 16.2ms\n",
      "Speed: 3.4ms preprocess, 16.2ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 traffic lights, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 traffic lights, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 traffic light, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 20.9ms\n",
      "Speed: 2.2ms preprocess, 20.9ms inference, 17.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 traffic light, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 traffic light, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 traffic light, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 1 traffic light, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 2 traffic lights, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 2 traffic lights, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 2 traffic lights, 10.2ms\n",
      "Speed: 4.0ms preprocess, 10.2ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 1 traffic light, 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 16.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 2 traffic lights, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 4 cars, 1 traffic light, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 1 traffic light, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 3 cars, 1 traffic light, 10.3ms\n",
      "Speed: 4.1ms preprocess, 10.3ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 3 cars, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 3 cars, 1 traffic light, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 traffic light, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 traffic light, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 traffic light, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 1 traffic light, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 1 traffic light, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 3 cars, 1 traffic light, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 traffic light, 1 suitcase, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 traffic light, 1 suitcase, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 1 suitcase, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 traffic light, 1 suitcase, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 1 suitcase, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 2 traffic lights, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 2 traffic lights, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 traffic light, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 16.5ms\n",
      "Speed: 2.6ms preprocess, 16.5ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 16.6ms\n",
      "Speed: 3.5ms preprocess, 16.6ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 2 traffic lights, 16.7ms\n",
      "Speed: 2.6ms preprocess, 16.7ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 15.9ms\n",
      "Speed: 3.0ms preprocess, 15.9ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 2 traffic lights, 18.1ms\n",
      "Speed: 4.6ms preprocess, 18.1ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 2 traffic lights, 15.9ms\n",
      "Speed: 2.8ms preprocess, 15.9ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 2 cars, 2 traffic lights, 15.1ms\n",
      "Speed: 2.6ms preprocess, 15.1ms inference, 13.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 2 traffic lights, 1 stop sign, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 13.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 traffic light, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 1 traffic light, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 2 traffic lights, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 car, 1 traffic light, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 2 traffic lights, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 2 traffic lights, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 2 traffic lights, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 2 traffic lights, 15.2ms\n",
      "Speed: 2.7ms preprocess, 15.2ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 2 traffic lights, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 15.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 1 traffic light, 1 stop sign, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 2 traffic lights, 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 2 traffic lights, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 traffic lights, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 1 stop sign, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 1 stop sign, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 1 traffic light, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 traffic light, 1 stop sign, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 1 traffic light, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 1 traffic light, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 traffic light, 1 stop sign, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 1 traffic light, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 2 traffic lights, 1 handbag, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 1 traffic light, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 1 traffic light, 1 stop sign, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 traffic light, 1 umbrella, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 traffic light, 18.3ms\n",
      "Speed: 2.9ms preprocess, 18.3ms inference, 20.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 stop sign, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 stop sign, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 traffic lights, 1 stop sign, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 stop sign, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.5ms\n",
      "Speed: 3.1ms preprocess, 16.5ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 traffic light, 16.2ms\n",
      "Speed: 2.8ms preprocess, 16.2ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 16.7ms\n",
      "Speed: 2.4ms preprocess, 16.7ms inference, 13.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 20.2ms\n",
      "Speed: 3.0ms preprocess, 20.2ms inference, 12.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 stop sign, 18.6ms\n",
      "Speed: 3.5ms preprocess, 18.6ms inference, 13.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 17.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 traffic light, 1 stop sign, 16.1ms\n",
      "Speed: 2.9ms preprocess, 16.1ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 1 stop sign, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 traffic light, 1 stop sign, 16.2ms\n",
      "Speed: 3.4ms preprocess, 16.2ms inference, 12.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 traffic light, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 stop sign, 16.0ms\n",
      "Speed: 2.8ms preprocess, 16.0ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.5ms preprocess, 15.8ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 15.3ms\n",
      "Speed: 3.7ms preprocess, 15.3ms inference, 14.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.8ms preprocess, 15.9ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 13.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 15.8ms\n",
      "Speed: 2.5ms preprocess, 15.8ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 12.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.5ms\n",
      "Speed: 2.6ms preprocess, 15.5ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 umbrella, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 umbrella, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 umbrella, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 umbrella, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 umbrella, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 stop sign, 1 umbrella, 14.1ms\n",
      "Speed: 2.5ms preprocess, 14.1ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 stop sign, 1 potted plant, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 stop sign, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 22.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 stop sign, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 1 stop sign, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 13.2ms\n",
      "Speed: 3.1ms preprocess, 13.2ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 10.3ms\n",
      "Speed: 4.2ms preprocess, 10.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 stop sign, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 car, 1 stop sign, 1 chair, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 1 chair, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 2 chairs, 1 potted plant, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 1 potted plant, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 1 potted plant, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 1 potted plant, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 1 potted plant, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 18.0ms\n",
      "Speed: 2.7ms preprocess, 18.0ms inference, 14.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 1 chair, 1 potted plant, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 19.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 14.3ms\n",
      "Speed: 2.6ms preprocess, 14.3ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 stop sign, 1 chair, 1 potted plant, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 1 potted plant, 13.3ms\n",
      "Speed: 1.9ms preprocess, 13.3ms inference, 19.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 16.9ms\n",
      "Speed: 3.5ms preprocess, 16.9ms inference, 14.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 chair, 16.7ms\n",
      "Speed: 2.3ms preprocess, 16.7ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 chair, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 chair, 16.9ms\n",
      "Speed: 3.4ms preprocess, 16.9ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 chair, 16.7ms\n",
      "Speed: 2.3ms preprocess, 16.7ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 chair, 1 potted plant, 16.8ms\n",
      "Speed: 2.4ms preprocess, 16.8ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 chair, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 chair, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 potted plant, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 17.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 1 potted plant, 16.0ms\n",
      "Speed: 2.8ms preprocess, 16.0ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 chair, 16.2ms\n",
      "Speed: 4.2ms preprocess, 16.2ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 1 chair, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 stop sign, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 13.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 21.4ms\n",
      "Speed: 2.3ms preprocess, 21.4ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.2ms\n",
      "Speed: 3.1ms preprocess, 16.2ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 traffic light, 1 stop sign, 16.4ms\n",
      "Speed: 3.2ms preprocess, 16.4ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 15.9ms\n",
      "Speed: 3.4ms preprocess, 15.9ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.7ms\n",
      "Speed: 4.1ms preprocess, 15.7ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 1 stop sign, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 potted plant, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.9ms preprocess, 15.8ms inference, 11.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.5ms preprocess, 15.8ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.6ms\n",
      "Speed: 2.9ms preprocess, 16.6ms inference, 22.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.7ms preprocess, 15.9ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 15.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.0ms\n",
      "Speed: 2.7ms preprocess, 15.0ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.6ms preprocess, 15.8ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 stop sign, 15.9ms\n",
      "Speed: 2.7ms preprocess, 15.9ms inference, 11.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 1 backpack, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 14.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 17.4ms\n",
      "Speed: 3.4ms preprocess, 17.4ms inference, 16.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 stop sign, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 persons, 1 stop sign, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 1 stop sign, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 16.9ms\n",
      "Speed: 11.7ms preprocess, 16.9ms inference, 16.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 handbag, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 1 stop sign, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 backpack, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 1 backpack, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 20.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 12.1ms\n",
      "Speed: 1.8ms preprocess, 12.1ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 stop sign, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 stop sign, 1 umbrella, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 umbrella, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 umbrella, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 1 umbrella, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 handbag, 17.4ms\n",
      "Speed: 3.0ms preprocess, 17.4ms inference, 10.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 handbag, 19.3ms\n",
      "Speed: 2.9ms preprocess, 19.3ms inference, 16.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 handbag, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 umbrella, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 umbrella, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 14.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.3ms\n",
      "Speed: 3.5ms preprocess, 16.3ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 clock, 16.2ms\n",
      "Speed: 2.9ms preprocess, 16.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 12.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 handbag, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.2ms\n",
      "Speed: 2.9ms preprocess, 16.2ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 17.9ms\n",
      "Speed: 3.5ms preprocess, 17.9ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 19.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 10.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 15.5ms\n",
      "Speed: 2.4ms preprocess, 15.5ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 persons, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 18.5ms\n",
      "Speed: 4.0ms preprocess, 18.5ms inference, 17.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 13.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.3ms\n",
      "Speed: 4.2ms preprocess, 16.3ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 stop sign, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 suitcases, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 suitcase, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 handbags, 1 suitcase, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 suitcase, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 suitcase, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 17.3ms\n",
      "Speed: 2.7ms preprocess, 17.3ms inference, 14.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 handbag, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 stop sign, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 handbag, 16.1ms\n",
      "Speed: 2.8ms preprocess, 16.1ms inference, 14.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 15.5ms\n",
      "Speed: 3.3ms preprocess, 15.5ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 2 handbags, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 2 handbags, 15.4ms\n",
      "Speed: 3.1ms preprocess, 15.4ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 2 handbags, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 3 handbags, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 4 handbags, 17.8ms\n",
      "Speed: 2.2ms preprocess, 17.8ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 handbags, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 15.7ms\n",
      "Speed: 2.5ms preprocess, 15.7ms inference, 12.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 15.2ms\n",
      "Speed: 2.8ms preprocess, 15.2ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 16.9ms\n",
      "Speed: 2.2ms preprocess, 16.9ms inference, 14.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 train, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 trains, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 trains, 21.7ms\n",
      "Speed: 2.2ms preprocess, 21.7ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 12.9ms\n",
      "Speed: 3.1ms preprocess, 12.9ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 train, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 train, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 18.2ms\n",
      "Speed: 2.7ms preprocess, 18.2ms inference, 12.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 14.3ms\n",
      "Speed: 3.1ms preprocess, 14.3ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 1 train, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 12.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 1 train, 16.2ms\n",
      "Speed: 3.0ms preprocess, 16.2ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 15.5ms\n",
      "Speed: 2.4ms preprocess, 15.5ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 motorcycle, 1 train, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 15.4ms\n",
      "Speed: 2.8ms preprocess, 15.4ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 9.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 15.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 13.4ms\n",
      "Speed: 2.6ms preprocess, 13.4ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 bicycles, 1 train, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 bus, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 12.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 17.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 bicycles, 1 train, 16.1ms\n",
      "Speed: 3.1ms preprocess, 16.1ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 bicycles, 1 train, 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 bicycles, 1 bus, 2 trains, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 10.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 1 bus, 1 train, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 bus, 2 trains, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 bus, 2 trains, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 bus, 1 train, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 bicycles, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 motorcycle, 1 train, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 8.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 motorcycle, 1 train, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 bicycles, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 bicycles, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 bicycles, 1 motorcycle, 1 train, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 bicycles, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 bicycles, 1 train, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 train, 18.2ms\n",
      "Speed: 3.2ms preprocess, 18.2ms inference, 18.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 train, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.5ms\n",
      "Speed: 2.4ms preprocess, 16.5ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 motorcycle, 19.4ms\n",
      "Speed: 4.4ms preprocess, 19.4ms inference, 14.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 1 motorcycle, 16.5ms\n",
      "Speed: 2.7ms preprocess, 16.5ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 motorcycle, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 motorcycle, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 motorcycle, 16.6ms\n",
      "Speed: 2.5ms preprocess, 16.6ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 motorcycle, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 motorcycle, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 16.6ms\n",
      "Speed: 3.1ms preprocess, 16.6ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 motorcycle, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 motorcycle, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 1 train, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 1 train, 18.6ms\n",
      "Speed: 2.6ms preprocess, 18.6ms inference, 17.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 1 train, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 1 umbrella, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 2 handbags, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 15.4ms\n",
      "Speed: 3.1ms preprocess, 15.4ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 bicycle, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 5.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 bicycle, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 bicycle, 15.5ms\n",
      "Speed: 4.1ms preprocess, 15.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 11.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 16.9ms\n",
      "Speed: 2.8ms preprocess, 16.9ms inference, 13.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 28.8ms\n",
      "Speed: 2.8ms preprocess, 28.8ms inference, 23.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 bicycle, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 bicycle, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 bicycle, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 tie, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 5.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 umbrella, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 18.0ms\n",
      "Speed: 2.3ms preprocess, 18.0ms inference, 13.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 suitcase, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 suitcase, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.1ms\n",
      "Speed: 3.2ms preprocess, 16.1ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.4ms\n",
      "Speed: 2.9ms preprocess, 16.4ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.2ms\n",
      "Speed: 3.2ms preprocess, 15.2ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 handbag, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 umbrella, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 handbag, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 suitcase, 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 14.0ms\n",
      "Speed: 3.2ms preprocess, 14.0ms inference, 11.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 14.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 11.5ms\n",
      "Speed: 5.8ms preprocess, 11.5ms inference, 9.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 14.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 11.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 car, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 car, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 bicycle, 1 car, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 17.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 13.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.7ms\n",
      "Speed: 2.5ms preprocess, 16.7ms inference, 18.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.5ms\n",
      "Speed: 3.2ms preprocess, 16.5ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.5ms\n",
      "Speed: 2.2ms preprocess, 16.5ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.5ms\n",
      "Speed: 2.3ms preprocess, 16.5ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 tie, 16.5ms\n",
      "Speed: 2.2ms preprocess, 16.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 tie, 16.5ms\n",
      "Speed: 3.6ms preprocess, 16.5ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 tie, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 tie, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.1ms\n",
      "Speed: 2.8ms preprocess, 16.1ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 8.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.0ms\n",
      "Speed: 3.4ms preprocess, 16.0ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.0ms\n",
      "Speed: 2.8ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 tie, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 tie, 17.6ms\n",
      "Speed: 2.7ms preprocess, 17.6ms inference, 14.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 tie, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 tie, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 tie, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 tie, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 10.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 3.0ms preprocess, 16.2ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.5ms\n",
      "Speed: 2.6ms preprocess, 16.5ms inference, 17.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.5ms\n",
      "Speed: 2.8ms preprocess, 16.5ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 19.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.1ms\n",
      "Speed: 4.5ms preprocess, 16.1ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 umbrella, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 umbrella, 16.0ms\n",
      "Speed: 3.5ms preprocess, 16.0ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 umbrellas, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 umbrella, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 9.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 umbrellas, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 umbrellas, 18.0ms\n",
      "Speed: 2.9ms preprocess, 18.0ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 16.1ms\n",
      "Speed: 3.4ms preprocess, 16.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 19.5ms\n",
      "Speed: 3.0ms preprocess, 19.5ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.3ms\n",
      "Speed: 2.7ms preprocess, 15.3ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 5.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 13.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 handbag, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 12.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 handbag, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 5.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 5.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 umbrella, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 umbrella, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 umbrella, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 truck, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 truck, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 truck, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 16.3ms\n",
      "Speed: 3.7ms preprocess, 16.3ms inference, 11.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 18.1ms\n",
      "Speed: 2.9ms preprocess, 18.1ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 11.4ms\n",
      "Speed: 4.7ms preprocess, 11.4ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 11.8ms\n",
      "Speed: 3.6ms preprocess, 11.8ms inference, 5.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 5.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 4.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 13.0ms\n",
      "Speed: 2.8ms preprocess, 13.0ms inference, 4.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 truck, 19.8ms\n",
      "Speed: 2.3ms preprocess, 19.8ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 umbrella, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 umbrella, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 5.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 umbrella, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 5.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 5.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 5.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 5.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 4.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 umbrella, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 14.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 4.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 4 persons, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 4.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 5.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 16.6ms\n",
      "Speed: 2.7ms preprocess, 16.6ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 16.6ms\n",
      "Speed: 2.8ms preprocess, 16.6ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 18.8ms\n",
      "Speed: 3.6ms preprocess, 18.8ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 umbrella, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 umbrella, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 5.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 umbrella, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 umbrella, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 4.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 umbrella, 18.1ms\n",
      "Speed: 3.1ms preprocess, 18.1ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 umbrella, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 2 cars, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 1 umbrella, 16.1ms\n",
      "Speed: 2.8ms preprocess, 16.1ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 1 umbrella, 16.2ms\n",
      "Speed: 3.0ms preprocess, 16.2ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 1 umbrella, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 4 persons, 1 car, 1 umbrella, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 5.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 4 persons, 1 car, 1 umbrella, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 5.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 15.3ms\n",
      "Speed: 2.8ms preprocess, 15.3ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 umbrella, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 5.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 7.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 18.2ms\n",
      "Speed: 3.1ms preprocess, 18.2ms inference, 12.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 2 cars, 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 16.8ms\n",
      "Speed: 2.7ms preprocess, 16.8ms inference, 11.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 1 umbrella, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 5 persons, 1 car, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 7.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 15.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 2 cars, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 2 cars, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 10.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 10.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 3 cars, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 2 cars, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 9.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 14.7ms\n",
      "Speed: 2.2ms preprocess, 14.7ms inference, 14.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 13.9ms\n",
      "Speed: 2.2ms preprocess, 13.9ms inference, 12.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 21.0ms\n",
      "Speed: 4.4ms preprocess, 21.0ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 9.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 16.5ms\n",
      "Speed: 2.6ms preprocess, 16.5ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 9.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 9.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 9.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 8.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 15.2ms\n",
      "Speed: 2.8ms preprocess, 15.2ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 16.2ms\n",
      "Speed: 3.1ms preprocess, 16.2ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 18.3ms\n",
      "Speed: 2.7ms preprocess, 18.3ms inference, 15.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.1ms\n",
      "Speed: 2.9ms preprocess, 16.1ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 8.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 8.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 16.0ms\n",
      "Speed: 2.8ms preprocess, 16.0ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 15.3ms\n",
      "Speed: 3.2ms preprocess, 15.3ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 2 cars, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 6 persons, 1 car, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 9.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 11.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 7 persons, 1 car, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 7.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 1 handbag, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 10.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 8 persons, 1 car, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 15.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 persons, 1 car, 1 handbag, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 14.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 9 persons, 1 car, 1 handbag, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 12.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 persons, 1 car, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 9.2ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "model = YOLO(\"runs/detect/train7/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(\"test.mp4\")\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "    res = model(frame, imgsz=512, conf=0.4)[0]\n",
    "    for b in res.boxes:\n",
    "        x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "        cls = int(b.cls[0])\n",
    "        conf = float(b.conf[0])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{model.names[cls]} {conf*100:.1f}%\", (x1, y1 - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Detections\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0199817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ulgen-yolo-object-det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
